{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "653ea5a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Author: Claire Wagner\n",
    "# Purpose: To generate data about city-owned PINs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d447d090",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import urllib.parse\n",
    "import datetime\n",
    "import json\n",
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ad284ebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "app_token = \"yo0POz8pPZyyDO9jOvtesb42J\" # CW - HEI Leaflet Map App Token\n",
    "limit = 3000000\n",
    "city_owned_api_info = { \"domain\" : \"https://data.cityofchicago.org\", \"dataset\" : \"aksk-kvfp\" }\n",
    "properties_api_info = { \"domain\" : \"https://datacatalog.cookcountyil.gov\", \"dataset\" : \"c49d-89sn\" }\n",
    "business_licenses_api_info = { \"domain\" : \"https://data.cityofchicago.org\", \"dataset\" : \"uupf-x98q\" }\n",
    "ward_boundaries_2015_to_2023_api_info = { \"domain\" : \"https://data.cityofchicago.org\", \"dataset\" : \"k9yb-bpqx\" }\n",
    "ward_boundaries_2023_api_info = { \"domain\" : \"https://data.cityofchicago.org\", \"dataset\" : \"p293-wvbd\" }\n",
    "neighborhood_boundaries_api_info = { \"domain\" : \"https://data.cityofchicago.org\", \"dataset\" : \"y6yq-dbs2\" }\n",
    "zoning_districts_api_info = { \"domain\" : \"https://data.cityofchicago.org\", \"dataset\" : \"dj47-wfun\" }\n",
    "ward_offices_api_info = { \"domain\" : \"https://data.cityofchicago.org\", \"dataset\" : \"htai-wnw4\" }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1b23473d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate attribution string that gives the URLs and the access date and time for the data sources.\n",
    "fetchtime = datetime.datetime.now(datetime.timezone.utc).strftime(\"%d %b %Y\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "04a74478",
   "metadata": {},
   "outputs": [],
   "source": [
    "def makeAPIRequest(api_endpoint, params, limit, read_function):\n",
    "    \"\"\"Helper function to make Socrata API request.\"\"\"\n",
    "    query = \"?\"\n",
    "    if len(params) > 0:\n",
    "        query += \"&\".join(params) + \"&\"\n",
    "    query += \"$limit=\" + str(limit) + \"&$$app_token=\" + app_token\n",
    "    return read_function(api_endpoint + urllib.parse.quote(query, safe=\"&?$=,!()\"))\n",
    "\n",
    "def get_url_response(url):\n",
    "    with urllib.request.urlopen(url) as response:\n",
    "        if response.status == 200:\n",
    "            return response.read()\n",
    "        else:\n",
    "            return None\n",
    "\n",
    "def get_metadata(api_info):\n",
    "    def get_original_metadata(domain, dataset, actual_datasource_uri = None):\n",
    "        original_metadata = json.loads(makeAPIRequest(\n",
    "            api_endpoint = domain + \"/api/views/metadata/v1/\" + dataset + \".json\",\n",
    "            params = [],\n",
    "            limit = limit,\n",
    "            read_function = get_url_response\n",
    "        ))\n",
    "        # if this isn't the full metadata for this dataset, use the provided \"reviewableUid\" as the metadata\n",
    "        # while providing information about the actual original datasource\n",
    "        if \"approvals\" in original_metadata and \"reviewableUid\" in original_metadata[\"approvals\"][-1]:\n",
    "            print(f\"reviewableUid found for {original_metadata['name']}\")\n",
    "            return get_original_metadata(\n",
    "                domain,\n",
    "                original_metadata[\"approvals\"][-1][\"reviewableUid\"],\n",
    "                original_metadata[\"actualDatasourceUri\"] if \"actualDatasourceUri\" in original_metadata else original_metadata[\"dataUri\"],\n",
    "            )\n",
    "        else:\n",
    "            # we've found the correct metadata to use, so include actual_datasource_uri in the metadata\n",
    "            if actual_datasource_uri != None:\n",
    "                original_metadata[\"actualDatasourceUri\"] = actual_datasource_uri\n",
    "            return original_metadata\n",
    "    # get metadata\n",
    "    original_metadata = get_original_metadata(api_info[\"domain\"], api_info[\"dataset\"])\n",
    "    # edit metadata for return\n",
    "    edited_metadata = { key: original_metadata[key] if key in original_metadata else None for key in [\n",
    "        \"id\", \"name\", \"description\", \"dataUri\", \"attribution\", \"attributionLink\", \"actualDatasourceUri\",\n",
    "    ] }\n",
    "    for key in [\"createdAt\", \"dataUpdatedAt\", \"metadataUpdatedAt\"]:\n",
    "        if (key not in original_metadata or original_metadata[key] == None):\n",
    "            edited_metadata[key] = None\n",
    "        else:\n",
    "            edited_metadata[key] = datetime.datetime.fromisoformat(original_metadata[key].split('T')[0]).strftime(\"%d %b %Y\")\n",
    "    edited_metadata[\"accessedOn\"] = fetchtime\n",
    "    return edited_metadata\n",
    "\n",
    "def standardize_columns(df):\n",
    "    \"\"\"standardize the names of all columns in df by making them lowercase and snake_case\"\"\"\n",
    "    df.columns = df.columns.str.lower().str.split().str.join('_')\n",
    "    \n",
    "def get_dataset_url(api_info, suffix):\n",
    "    return api_info[\"domain\"] + \"/resource/\" + api_info[\"dataset\"] + \".\" + suffix\n",
    "\n",
    "def get_geojson_data(api_info):\n",
    "    output = {}\n",
    "    output[\"data\"] = json.loads(makeAPIRequest(\n",
    "        api_endpoint = get_dataset_url(api_info, \"geojson\"),\n",
    "        params = [],\n",
    "        limit = limit,\n",
    "        read_function = get_url_response\n",
    "    ))\n",
    "    output[\"metadata\"] = get_metadata(api_info)\n",
    "    return output\n",
    "\n",
    "\"\"\"Aggregate x by returning a list of all unique, non-null values in x in the order they were encountered\n",
    "(or, if there is only one unique value in x, returning that value)\"\"\"\n",
    "def set_aggregation_function(x):\n",
    "    xSet = OrderedDict()\n",
    "    for item in x:\n",
    "        if not pd.isna(item):\n",
    "            xSet[item] = None\n",
    "    xList = list(xSet.keys())\n",
    "    xListLen = len(xList)\n",
    "    if xListLen == 0:\n",
    "        return None\n",
    "    elif xListLen == 1:\n",
    "        return xList[0]\n",
    "    else:\n",
    "        return xList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "849187ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fetch data from the Property Locations dataset about all properties in Wards 1-50\n",
    "properties = makeAPIRequest(\n",
    "    api_endpoint = get_dataset_url(properties_api_info, \"json\"),\n",
    "    params = [\n",
    "        \"$select=pin, property_address, property_zip, ward, longitude, latitude, tract_geoid\",\n",
    "        \"$where=(latitude IS NOT NULL) AND (longitude IS NOT NULL)\",\n",
    "    ],\n",
    "    limit = limit,\n",
    "    read_function = pd.read_json,\n",
    ")\n",
    "properties_metadata = get_metadata(properties_api_info)\n",
    "properties_metadata[\"dataUseNotes\"] = \"Used to obtain location information for PINs in Cook County.\"\n",
    "\n",
    "properties[\"pin\"] = properties[\"pin\"].apply(str).str.rjust(14, '0')\n",
    "\n",
    "with open(\"../data/misc/misc.js\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(\"const property_locations_metadata = \")\n",
    "    f.write(json.dumps(properties_metadata) + \";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5ee6c294",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ward_boundaries():\n",
    "    print(\"Getting data for ward boundaries\")\n",
    "    with open(\"../data/geojson/ward_boundaries.js\", \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(\"const ward_boundaries_2015_to_2023 = \")\n",
    "        f.write(json.dumps(get_geojson_data(ward_boundaries_2015_to_2023_api_info)) + \";\")\n",
    "        f.write(\"\\n\\nconst ward_boundaries_2023 = \")\n",
    "        f.write(json.dumps(get_geojson_data(ward_boundaries_2023_api_info)) + \";\")\n",
    "    print(\"Finished getting data for ward boundaries\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f35ac128",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_neighborhood_boundaries():\n",
    "    print(\"Getting data for neighborhood boundaries\")\n",
    "    with open(\"../data/geojson/neighborhood_boundaries.js\", \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(\"const neighborhood_boundaries = \")\n",
    "        f.write(json.dumps(get_geojson_data(neighborhood_boundaries_api_info)) + \";\")\n",
    "    print(\"Finished getting data for neighborhood boundaries\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3c634897",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_zoning_districts():\n",
    "    print(\"Getting data for zoning districts\")\n",
    "    with open(\"../data/geojson/zoning_districts.js\", \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(\"const zoning_districts = \")\n",
    "        f.write(json.dumps(get_geojson_data(zoning_districts_api_info)) + \";\")\n",
    "    print(\"Finished getting data for zoning districts\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2331246b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_individual_properties():\n",
    "    print(\"Getting data for individual properties\")\n",
    "    # fetch location info for Sunshine Gospel Ministries address (source: https://www.sunshinegospel.org/)\n",
    "    sgmAddress = \"500 E 61st St\".lower()\n",
    "    # get location data for Sunshine Gospel Ministries\n",
    "    sgm = makeAPIRequest(\n",
    "        api_endpoint = get_dataset_url(properties_api_info, \"json\"),\n",
    "        params = [\n",
    "            \"$select=pin, property_address, longitude, latitude\",\n",
    "            f\"$where=lower(property_address)='{sgmAddress}'\",\n",
    "        ],\n",
    "        limit = 1,\n",
    "        read_function = pd.read_json,\n",
    "    ).loc[0]\n",
    "    \n",
    "    ward_20_office = makeAPIRequest(\n",
    "        api_endpoint = get_dataset_url(ward_offices_api_info, \"json\"),\n",
    "        params = [\n",
    "            \"$select=ward, alderman, address, location\",\n",
    "            \"$where=ward=20\",\n",
    "        ],\n",
    "        limit = 1,\n",
    "        read_function = pd.read_json,\n",
    "    ).loc[0]\n",
    "    ward_20_office[\"latitude\"] = ward_20_office[\"location\"].get(\"latitude\")\n",
    "    ward_20_office[\"longitude\"] = ward_20_office[\"location\"].get(\"longitude\")\n",
    "    ward_20_office = ward_20_office.drop(labels=[\"location\"])\n",
    "    \n",
    "    ward_offices_metadata = get_metadata(ward_offices_api_info)\n",
    "    ward_offices_metadata[\"dataUseNotes\"] = \"Used to obtain location information for the Ward 20 office.\"\n",
    "        \n",
    "    with open(\"../data/misc/individual_properties.js\", \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(\"const sunshine_gospel = \")\n",
    "        f.write(sgm.to_json(orient=\"index\") + \";\")\n",
    "        f.write(\"\\n\\nconst ward_20_office = \")\n",
    "        f.write(ward_20_office.to_json(orient=\"index\") + \";\")\n",
    "        f.write(\"\\n\\nconst ward_offices_metadata = \")\n",
    "        f.write(json.dumps(ward_offices_metadata) + \";\")\n",
    "    print(\"Finished getting data for individual properties\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "fae2fa09",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_city_owned():\n",
    "    print(\"Getting data for city-owned properties\")\n",
    "    # fetch data from the City-Owned Land Inventory dataset about all properties currently owned by the City of Chicago that might be up for sale (see http://dev.cityofchicago.org/open%20data/data%20portal/2020/08/11/city-owned-property.html)\n",
    "    city_owned = makeAPIRequest(\n",
    "        api_endpoint = get_dataset_url(city_owned_api_info, \"json\"),\n",
    "        params = [\n",
    "            \"$select=pin, managing_organization, lower(property_status) AS property_status, date_of_acquisition, date_of_disposition, sq_ft, last_update\",\n",
    "            \"$where=(lower(property_status)='owned by city') AND (lower(managing_organization)='none' OR managing_organization IS NULL)\",\n",
    "        ],\n",
    "        limit = limit,\n",
    "        read_function = pd.read_json,\n",
    "    )\n",
    "    city_owned_metadata = get_metadata(city_owned_api_info)\n",
    "    \n",
    "    city_owned[\"pin\"] = city_owned[\"pin\"].str.replace(\"-\",\"\")\n",
    "    city_owned_join = pd.merge(city_owned, properties, how=\"inner\", on=\"pin\", suffixes = [\"_aksk-kvfp\", \"_c49d-89sn\"])\n",
    "    count_of_no_updated_location_info = city_owned.shape[0] - city_owned_join.shape[0]\n",
    "    print(\"number of city-owned properties for which no location data from properties could be found:\", count_of_no_updated_location_info)\n",
    "\n",
    "    city_owned_metadata[\"dataUseNotes\"] = 'Only PINs where \"property_status\" is \"owned by city\" and' \\\n",
    "    + ' \"managing_organization\" is \"none\" or blank (using case-insensitive matching) have been included on the map' \\\n",
    "    + ' (based on the Open Data Portal Team\\'s' \\\n",
    "    + ' <a href=\"http://dev.cityofchicago.org/open%20data/data%20portal/2020/08/11/city-owned-property.html\">notes</a>' \\\n",
    "    + ' about the dataset). Up-to-date location information was obtained using the' \\\n",
    "    + f' <a href={properties_metadata[\"dataUri\"]}>\"{properties_metadata[\"name\"]}\"</a> dataset' \\\n",
    "    + f' ({count_of_no_updated_location_info} PINs for which no up-to-date location information could be found have been excluded).'\n",
    "    \n",
    "    city_owned_join.filter(items=[\n",
    "        \"pin\",\n",
    "        \"managing_organization\",\n",
    "        \"property_status\",\n",
    "        \"last_update\",\n",
    "        \"date_of_acquisition\",\n",
    "        \"date_of_disposition\",\n",
    "        \"property_address\",\n",
    "        \"property_zip\",\n",
    "        \"ward\",\n",
    "        \"tract_geoid\",\n",
    "    ]).to_excel(\"city_owned_pins_possibly_for_sale.xlsx\", index=False)\n",
    "\n",
    "    city_owned_join = city_owned_join.set_index(\"pin\", drop=False)\n",
    "    \n",
    "    with open(\"../data/city-owned/city_owned_data.js\", \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(\"const city_owned_data = \")\n",
    "        f.write(city_owned_join.to_json(orient=\"index\") + \";\")\n",
    "        f.write(\"\\n\\nconst city_owned_metadata = \")\n",
    "        f.write(json.dumps(city_owned_metadata) + \";\")\n",
    "    print(\"Finished getting data for city-owned properties\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9b2885cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_business_licenses():\n",
    "    print(\"Getting data for business licenses\")\n",
    "    business_licenses = makeAPIRequest(\n",
    "        api_endpoint = get_dataset_url(business_licenses_api_info, \"json\"),\n",
    "        params = [\n",
    "            \"$select=license_number, license_id AS license_record_id, doing_business_as_name, license_description, business_activity, address, ward, zip_code, longitude, latitude, license_start_date\",\n",
    "            \"$where=city='CHICAGO' AND (latitude IS NOT NULL) AND (longitude IS NOT NULL)\",\n",
    "        ],\n",
    "        limit = limit,\n",
    "        read_function = pd.read_json,\n",
    "    )\n",
    "    business_licenses_metadata = get_metadata(business_licenses_api_info)\n",
    "    business_licenses_metadata[\"dataUseNotes\"] = 'Only PINs with valid coordinates where \"city\" is \"CHICAGO\" have been included on the map.'\n",
    "    \n",
    "    # filter out duplicate entries for the same license number, keeping only the entry with the most recent license start date\n",
    "    business_licenses_filtered = business_licenses.sort_values(by=['license_number', 'license_start_date']).drop_duplicates(subset=['license_number'], keep='last').drop(columns=['license_start_date'])\n",
    "    # check that each license number is unique\n",
    "    assert business_licenses_filtered.shape[0] == business_licenses_filtered['license_number'].unique().shape[0]\n",
    "    \n",
    "    # aggregate licenses into a single entry for each address of each business\n",
    "    business_licenses_aggregated = business_licenses_filtered.groupby(by=[\"doing_business_as_name\", \"address\"]).agg(set_aggregation_function).reset_index()    \n",
    "    with open(\"../data/business-licenses/business_license_data.js\", \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(\"const business_license_data = \")\n",
    "        f.write(business_licenses_aggregated.to_json(orient=\"records\") + \";\")\n",
    "        f.write(\"\\n\\nconst business_licenses_metadata = \")\n",
    "        f.write(json.dumps(business_licenses_metadata) + \";\")\n",
    "    print(\"Finished getting data for business licenses\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4f3d4740",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_scavenger_sale():\n",
    "    print(\"Getting data for scavenger sale\")\n",
    "    # scavenger sale data from 28 January 2022 (source: https://web.archive.org/web/20220128184252/https://www.cookcountytreasurer.com/pdfs/scavsale/2022cookcountyscavengertaxsalelist.xlsx, accessed 3 June 2022)\n",
    "    scavenger = pd.read_excel(\"../data/scavenger-sale/2022cookcountyscavengertaxsalelist_1-28-22.xlsx\")\n",
    "    standardize_columns(scavenger)\n",
    "    scavenger[\"pin\"] = scavenger[\"pin\"].str.replace(\"-\", \"\")\n",
    "    scavenger[\"classification\"] = scavenger[\"classification\"].str.strip()\n",
    "    \n",
    "    # property class data (source: https://www.cookcountyassessor.com/form-document/codes-classification-property, accessed 22 June 2022)\n",
    "    property_classes = pd.read_excel(\"../data/scavenger-sale/property_classes.xlsx\")\n",
    "    # join scavenger sale data with property class data\n",
    "    scavenger_with_property_classes = pd.merge(scavenger, property_classes, how=\"left\", left_on = \"classification\", right_on=\"property_code\").drop(columns=['classification'])\n",
    "    # make sure all scavenger sale entries have associated property class data\n",
    "    assert scavenger_with_property_classes[pd.isna(scavenger_with_property_classes['property_code'])].shape[0] == 0\n",
    "    \n",
    "    # get location data for pins on scavenger sale list\n",
    "    scavenger_final_join = pd.merge(scavenger_with_property_classes, properties, how=\"inner\", on=\"pin\", suffixes=[\"_scavenger_sale\", \"_c49d-89sn\"])\n",
    "    # make sure all pins on scavenger sale list have associated location data\n",
    "    assert scavenger_final_join.shape[0] == scavenger_with_property_classes.shape[0]\n",
    "    scavenger_final_join = scavenger_final_join[scavenger_final_join['property_city'] == 'CHICAGO'].filter(items = [\n",
    "        'pin',\n",
    "        'property_address_scavenger_sale',\n",
    "        'ward',\n",
    "        'delinquent_tax_year_range',\n",
    "        'delinquent_tax',\n",
    "        'delinquent_interest',\n",
    "        'total_delinquency',\n",
    "        '2020_taxes_billed',\n",
    "        'property_code',\n",
    "        'property_code_meaning',\n",
    "        'property_code_class',\n",
    "        'property_zip',\n",
    "        'longitude',\n",
    "        'latitude',\n",
    "        'tract_geoid',\n",
    "    ]).rename(columns = {\n",
    "        'property_address_scavenger_sale' : 'property_address',\n",
    "    }).set_index('pin', drop=False)\n",
    "    # make sure there are no duplicated entries for pins\n",
    "    assert scavenger_final_join.index.unique().shape[0] == scavenger_final_join.index.shape[0]\n",
    "    \n",
    "    scavenger_sale_metadata = {\n",
    "        'id': None,\n",
    "        'name': '2022 Cook County Scavenger Tax Sale List',\n",
    "        'description': 'Properties scheduled to be offered at the 2022 Scavenger Sale.',\n",
    "        'dataUri': 'https://web.archive.org/web/20220128181637/https://www.cookcountytreasurer.com/scavengersalemap.aspx',\n",
    "        'attribution': 'Cook County Treasurer',\n",
    "        'attributionLink': 'https://www.cookcountytreasurer.com/',\n",
    "        'actualDatasourceUri': 'https://web.archive.org/web/20220128184252/https://www.cookcountytreasurer.com/pdfs/scavsale/2022cookcountyscavengertaxsalelist.xlsx',\n",
    "        'createdAt': None,\n",
    "        'dataUpdatedAt': '28 January 2022',\n",
    "        'metadataUpdatedAt': None,\n",
    "        'accessedOn': '3 Jun 2022',\n",
    "        'dataUseNotes': 'Only PINs where \"property_city\" is \"CHICAGO\" have been included on the map.' \\\n",
    "        + ' Location information was obtained using the' \\\n",
    "        + f' <a href={properties_metadata[\"dataUri\"]}>\"{properties_metadata[\"name\"]}\"</a> dataset.'\n",
    "    }\n",
    "    \n",
    "    property_classification_codes_metadata = {\n",
    "        'id': None,\n",
    "        'name': 'Definitions for the Codes for Classification of Real Property',\n",
    "        'description': 'Definitions for the codes for classification of real property.',\n",
    "        'dataUri': 'https://prodassets.cookcountyassessor.com/s3fs-public/form_documents/classcode.pdf?VersionId=12JVr.oX..WD4hfgjLCp5AIVfar71ndn',\n",
    "        'attribution': 'Cook County Assessor',\n",
    "        'attributionLink': 'https://www.cookcountyassessor.com/',\n",
    "        'actualDatasourceUri': None,\n",
    "        'createdAt': '03 April 2018',\n",
    "        'dataUpdatedAt': None,\n",
    "        'metadataUpdatedAt': None,\n",
    "        'accessedOn': '22 Jun 2022',\n",
    "    }\n",
    "    \n",
    "    with open(\"../data/scavenger-sale/scavenger_data.js\", \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(\"const scavenger_sale_data = \") # assign join JSON data to variable for easier access by JavaScript scripts in browser\n",
    "        f.write(scavenger_final_join.to_json(orient=\"index\") + \";\") # output as JSON\n",
    "        f.write(\"\\n\\nconst scavenger_sale_metadata = \")\n",
    "        f.write(json.dumps(scavenger_sale_metadata) + \";\")\n",
    "        f.write(\"\\n\\nconst property_classification_codes_metadata = \")\n",
    "        f.write(json.dumps(property_classification_codes_metadata) + \";\")\n",
    "    print(\"Finished getting data for scavenger sale\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "954745a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tax_sale_ward_20():\n",
    "    print(\"Getting data for Ward 20 tax sale\")\n",
    "    # Ward 20 Properties on Tax Sale list for Tax Year 2019, accessed on 17 May 2022 around 11 am ET\n",
    "    taxsale = pd.read_excel(\"../data/tax-sale/tax_sale_tax_year_2019_ward20_accessed_17_May_2022.xlsx\")\n",
    "    standardize_columns(taxsale)\n",
    "    taxsale['pin'] = taxsale['pin'].str.replace('-', '')\n",
    "    taxsale = taxsale.filter(items=[\n",
    "        'pin',\n",
    "        'property_address',\n",
    "        'current_mailing_address',\n",
    "        'taxpayer_name',\n",
    "        'tax_type',\n",
    "        'tax_year',\n",
    "        'total_tax_due',\n",
    "        'total_due_(including_interest)',\n",
    "        'classification',\n",
    "        'prior_tax_years_may_also_be_unpaid',\n",
    "    ])\n",
    "    taxsale = taxsale[taxsale['tax_year'] == 2019]\n",
    "    # make sure no entries have duplicate pins\n",
    "    assert taxsale['pin'].shape[0] == taxsale['pin'].unique().shape[0]\n",
    "    \n",
    "    taxsale_join = pd.merge(taxsale, properties, how=\"inner\", on=\"pin\", suffixes=[\"_tax_sale\", \"_c49d-89sn\"])\n",
    "    # make sure all pins have associated location data and are in Ward 20\n",
    "    assert taxsale_join.shape[0] == taxsale.shape[0]\n",
    "    assert taxsale_join.shape[0] == taxsale_join[taxsale_join['ward'] == 20].shape[0]\n",
    "    taxsale_join = taxsale_join.drop(columns=[\n",
    "        'property_address_c49d-89sn',\n",
    "    ]).rename(columns={\n",
    "        'property_address_tax_sale' : 'property_address',\n",
    "        'total_due_(including_interest)' : 'total_due_including_interest',\n",
    "    }).set_index('pin', drop=False)\n",
    "    \n",
    "    taxsale_ward20_metadata = {\n",
    "        'id': None,\n",
    "        'name': 'Ward 20 Delinquent Tax Report',\n",
    "        'description': 'Properties in Ward 20 with delinquent taxes for Tax Year 2019 (payable in 2020) that were eligible for the Annual Tax Sale that began May 12, 2022.',\n",
    "        'dataUri': 'https://www.cookcountytreasurer.com/delinquenttaxes.aspx',\n",
    "        'attribution': 'Cook County Treasurer',\n",
    "        'attributionLink': 'https://www.cookcountytreasurer.com/',\n",
    "        'actualDatasourceUri': None,\n",
    "        'createdAt': None,\n",
    "        'dataUpdatedAt': None,\n",
    "        'metadataUpdatedAt': None,\n",
    "        'accessedOn': '17 Jun 2022',\n",
    "        'dataUseNotes': 'Only PINs where \"tax_year\" is 2019 have been included on the map.' \\\n",
    "        + ' Location information was obtained using the' \\\n",
    "        + f' <a href={properties_metadata[\"dataUri\"]}>\"{properties_metadata[\"name\"]}\"</a> dataset.'\n",
    "    }\n",
    "    \n",
    "    with open(\"../data/tax-sale/tax_sale_ward20_tax_year_2019.js\", \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(\"const taxsale_ward20_data = \") # assign JSON data to variable for easier access by JavaScript scripts in browser\n",
    "        f.write(taxsale_join.to_json(orient=\"index\") + \";\") # output as JSON\n",
    "        f.write(\"\\n\\nconst taxsale_ward20_metadata = \")\n",
    "        f.write(json.dumps(taxsale_ward20_metadata) + \";\")\n",
    "    print(\"Finished getting data for Ward 20 tax sale\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "10c654e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting data for ward boundaries\n",
      "reviewableUid found for WARDS_2015\n",
      "Finished getting data for ward boundaries\n",
      "Getting data for neighborhood boundaries\n",
      "reviewableUid found for Neighborhoods_2012b\n",
      "Finished getting data for neighborhood boundaries\n",
      "Getting data for zoning districts\n",
      "reviewableUid found for zoning_2016_01\n",
      "Finished getting data for zoning districts\n",
      "Getting data for individual properties\n",
      "Finished getting data for individual properties\n",
      "Getting data for city-owned properties\n",
      "number of city-owned properties for which no location data from properties could be found: 6\n",
      "Finished getting data for city-owned properties\n",
      "Getting data for business licenses\n",
      "Finished getting data for business licenses\n",
      "Getting data for scavenger sale\n",
      "Finished getting data for scavenger sale\n",
      "Getting data for Ward 20 tax sale\n",
      "Finished getting data for Ward 20 tax sale\n"
     ]
    }
   ],
   "source": [
    "# comment out the functions that should not be called\n",
    "get_ward_boundaries()\n",
    "get_neighborhood_boundaries()\n",
    "get_zoning_districts()\n",
    "get_individual_properties()\n",
    "get_city_owned()\n",
    "get_business_licenses()\n",
    "get_scavenger_sale()\n",
    "get_tax_sale_ward_20()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afd7b5d9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

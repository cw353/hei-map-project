{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "653ea5a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Author: Claire Wagner\n",
    "# Purpose: To generate data about city-owned PINs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d447d090",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import urllib.parse\n",
    "import datetime\n",
    "import json\n",
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ad284ebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "app_token = \"yo0POz8pPZyyDO9jOvtesb42J\" # CW - HEI Leaflet Map App Token\n",
    "limit = 3000000\n",
    "city_owned_api_info = { \"domain\" : \"https://data.cityofchicago.org\", \"dataset\" : \"aksk-kvfp\" }\n",
    "properties_api_info = { \"domain\" : \"https://datacatalog.cookcountyil.gov\", \"dataset\" : \"c49d-89sn\" }\n",
    "business_licenses_api_info = { \"domain\" : \"https://data.cityofchicago.org\", \"dataset\" : \"uupf-x98q\" }\n",
    "ward_boundaries_2015_to_2023_api_info = { \"domain\" : \"https://data.cityofchicago.org\", \"dataset\" : \"k9yb-bpqx\" }\n",
    "ward_boundaries_2023_api_info = { \"domain\" : \"https://data.cityofchicago.org\", \"dataset\" : \"p293-wvbd\" }\n",
    "neighborhood_boundaries_api_info = { \"domain\" : \"https://data.cityofchicago.org\", \"dataset\" : \"y6yq-dbs2\" }\n",
    "zoning_districts_api_info = { \"domain\" : \"https://data.cityofchicago.org\", \"dataset\" : \"dj47-wfun\" }\n",
    "ward_offices_api_info = { \"domain\" : \"https://data.cityofchicago.org\", \"dataset\" : \"htai-wnw4\" }\n",
    "school_locations_api_info = { \"domain\" : \"https://data.cityofchicago.org\", \"dataset\" : \"vfmh-nkyk\" }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1b23473d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate attribution string that gives the URLs and the access date and time for the data sources.\n",
    "fetchtime = datetime.datetime.now(datetime.timezone.utc).strftime(\"%d %b %Y\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "04a74478",
   "metadata": {},
   "outputs": [],
   "source": [
    "def makeAPIRequest(api_endpoint, params, limit, read_function):\n",
    "    \"\"\"Helper function to make Socrata API request.\"\"\"\n",
    "    query = \"?\"\n",
    "    if len(params) > 0:\n",
    "        query += \"&\".join(params) + \"&\"\n",
    "    query += \"$limit=\" + str(limit) + \"&$$app_token=\" + app_token\n",
    "    return read_function(api_endpoint + urllib.parse.quote(query, safe=\"&?$=,!()\"))\n",
    "\n",
    "def get_url_response(url):\n",
    "    with urllib.request.urlopen(url) as response:\n",
    "        if response.status == 200:\n",
    "            return response.read()\n",
    "        else:\n",
    "            return None\n",
    "\n",
    "def get_metadata(api_info):\n",
    "    def get_original_metadata(domain, dataset, actual_datasource_uri = None):\n",
    "        original_metadata = json.loads(makeAPIRequest(\n",
    "            api_endpoint = domain + \"/api/views/metadata/v1/\" + dataset + \".json\",\n",
    "            params = [],\n",
    "            limit = limit,\n",
    "            read_function = get_url_response\n",
    "        ))\n",
    "        # if this isn't the full metadata for this dataset, use the provided \"reviewableUid\" as the metadata\n",
    "        # while providing information about the actual original datasource\n",
    "        if \"approvals\" in original_metadata and \"reviewableUid\" in original_metadata[\"approvals\"][-1]:\n",
    "            print(f\"reviewableUid found for {original_metadata['name']}\")\n",
    "            return get_original_metadata(\n",
    "                domain,\n",
    "                original_metadata[\"approvals\"][-1][\"reviewableUid\"],\n",
    "                original_metadata[\"actualDatasourceUri\"] if \"actualDatasourceUri\" in original_metadata else original_metadata[\"dataUri\"],\n",
    "            )\n",
    "        else:\n",
    "            # we've found the correct metadata to use, so include actual_datasource_uri in the metadata\n",
    "            if actual_datasource_uri != None:\n",
    "                original_metadata[\"actualDatasourceUri\"] = actual_datasource_uri\n",
    "            return original_metadata\n",
    "    # get metadata\n",
    "    original_metadata = get_original_metadata(api_info[\"domain\"], api_info[\"dataset\"])\n",
    "    # edit metadata for return\n",
    "    edited_metadata = { key: original_metadata[key] if key in original_metadata else None for key in [\n",
    "        \"id\", \"name\", \"description\", \"dataUri\", \"attribution\", \"attributionLink\", \"actualDatasourceUri\",\n",
    "    ] }\n",
    "    for key in [\"createdAt\", \"dataUpdatedAt\", \"metadataUpdatedAt\"]:\n",
    "        if (key not in original_metadata or original_metadata[key] == None):\n",
    "            edited_metadata[key] = None\n",
    "        else:\n",
    "            edited_metadata[key] = from_iso_format(original_metadata[key])\n",
    "    edited_metadata[\"accessedOn\"] = fetchtime\n",
    "    return edited_metadata\n",
    "\n",
    "def standardize_columns(df):\n",
    "    \"\"\"standardize the names of all columns in df by making them lowercase and snake_case\"\"\"\n",
    "    df.columns = df.columns.str.lower().str.split().str.join('_')\n",
    "    \n",
    "def get_dataset_url(api_info, suffix):\n",
    "    return api_info[\"domain\"] + \"/resource/\" + api_info[\"dataset\"] + \".\" + suffix\n",
    "\n",
    "def get_geojson_data(api_info):\n",
    "    output = {}\n",
    "    output[\"data\"] = json.loads(makeAPIRequest(\n",
    "        api_endpoint = get_dataset_url(api_info, \"geojson\"),\n",
    "        params = [],\n",
    "        limit = limit,\n",
    "        read_function = get_url_response\n",
    "    ))\n",
    "    output[\"metadata\"] = get_metadata(api_info)\n",
    "    return output\n",
    "\n",
    "def from_iso_format(date, formatString=\"%d %b %Y\"):\n",
    "    if pd.isna(date):\n",
    "        return None\n",
    "    else:\n",
    "        return datetime.datetime.fromisoformat(date.split('T')[0]).strftime(formatString)\n",
    "\n",
    "\"\"\"Aggregate x by returning a list of all unique, non-null values in x in the order they were encountered\n",
    "(or, if there is only one unique value in x, returning that value)\"\"\"\n",
    "def set_aggregation_function(x):\n",
    "    xSet = OrderedDict()\n",
    "    for item in x:\n",
    "        if not pd.isna(item):\n",
    "            xSet[item] = None\n",
    "    xList = list(xSet.keys())\n",
    "    xListLen = len(xList)\n",
    "    if xListLen == 0:\n",
    "        return None\n",
    "    elif xListLen == 1:\n",
    "        return xList[0]\n",
    "    else:\n",
    "        return xList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "849187ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fetch data from the Property Locations dataset about all properties in Wards 1-50\n",
    "properties = makeAPIRequest(\n",
    "    api_endpoint = get_dataset_url(properties_api_info, \"json\"),\n",
    "    params = [\n",
    "        \"$select=pin, property_address, property_zip, ward, longitude, latitude\",\n",
    "        \"$where=(latitude IS NOT NULL) AND (longitude IS NOT NULL)\",\n",
    "    ],\n",
    "    limit = limit,\n",
    "    read_function = pd.read_json,\n",
    ")\n",
    "properties_metadata = get_metadata(properties_api_info)\n",
    "properties_metadata[\"dataUseNotes\"] = \"Used to obtain location information for PINs in Cook County.\"\n",
    "\n",
    "properties[\"pin\"] = properties[\"pin\"].apply(str).str.rjust(14, '0')\n",
    "\n",
    "with open(\"../data/misc/misc.js\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(\"const property_locations_metadata = \")\n",
    "    f.write(json.dumps(properties_metadata) + \";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5ee6c294",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ward_boundaries():\n",
    "    print(\"Getting data for ward boundaries\")\n",
    "    with open(\"../data/geojson/ward_boundaries.js\", \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(\"const ward_boundaries_2015_to_2023 = \")\n",
    "        f.write(json.dumps(get_geojson_data(ward_boundaries_2015_to_2023_api_info)) + \";\")\n",
    "        f.write(\"\\n\\nconst ward_boundaries_2023 = \")\n",
    "        f.write(json.dumps(get_geojson_data(ward_boundaries_2023_api_info)) + \";\")\n",
    "    print(\"Finished getting data for ward boundaries\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f35ac128",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_neighborhood_boundaries():\n",
    "    print(\"Getting data for neighborhood boundaries\")\n",
    "    with open(\"../data/geojson/neighborhood_boundaries.js\", \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(\"const neighborhood_boundaries = \")\n",
    "        f.write(json.dumps(get_geojson_data(neighborhood_boundaries_api_info)) + \";\")\n",
    "    print(\"Finished getting data for neighborhood boundaries\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3c634897",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_zoning_districts():\n",
    "    print(\"Getting data for zoning districts\")\n",
    "    with open(\"../data/geojson/zoning_districts.js\", \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(\"const zoning_districts = \")\n",
    "        f.write(json.dumps(get_geojson_data(zoning_districts_api_info)) + \";\")\n",
    "    print(\"Finished getting data for zoning districts\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "389698ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_school_locations():\n",
    "    print(\"Getting data for school locations\")\n",
    "    with open(\"../data/geojson/school_locations.js\", \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(\"const school_locations = \")\n",
    "        f.write(json.dumps(get_geojson_data(school_locations_api_info)) + \";\")\n",
    "    print(\"Finished getting data for school_locations\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2331246b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_individual_properties():\n",
    "    print(\"Getting data for individual properties\")\n",
    "    # fetch location info for Sunshine Gospel Ministries address (source: https://www.sunshinegospel.org/)\n",
    "    sgmAddress = \"500 E 61st St\".lower()\n",
    "    # get location data for Sunshine Gospel Ministries\n",
    "    sgm = makeAPIRequest(\n",
    "        api_endpoint = get_dataset_url(properties_api_info, \"json\"),\n",
    "        params = [\n",
    "            \"$select=pin, property_address, longitude, latitude\",\n",
    "            f\"$where=lower(property_address)='{sgmAddress}'\",\n",
    "        ],\n",
    "        limit = 1,\n",
    "        read_function = pd.read_json,\n",
    "    ).loc[0]\n",
    "    \n",
    "    ward_20_office = makeAPIRequest(\n",
    "        api_endpoint = get_dataset_url(ward_offices_api_info, \"json\"),\n",
    "        params = [\n",
    "            \"$select=ward, address, location\",\n",
    "            \"$where=ward=20\",\n",
    "        ],\n",
    "        limit = 1,\n",
    "        read_function = pd.read_json,\n",
    "    ).loc[0]\n",
    "    ward_20_office[\"latitude\"] = ward_20_office[\"location\"].get(\"latitude\")\n",
    "    ward_20_office[\"longitude\"] = ward_20_office[\"location\"].get(\"longitude\")\n",
    "    ward_20_office = ward_20_office.drop(labels=[\"location\"])\n",
    "    \n",
    "    ward_offices_metadata = get_metadata(ward_offices_api_info)\n",
    "    ward_offices_metadata[\"dataUseNotes\"] = \"Used to obtain location information for the Ward 20 office.\"\n",
    "        \n",
    "    with open(\"../data/misc/individual_properties.js\", \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(\"const sunshine_gospel = \")\n",
    "        f.write(sgm.to_json(orient=\"index\") + \";\")\n",
    "        f.write(\"\\n\\nconst ward_20_office = \")\n",
    "        f.write(ward_20_office.to_json(orient=\"index\") + \";\")\n",
    "        f.write(\"\\n\\nconst ward_offices_metadata = \")\n",
    "        f.write(json.dumps(ward_offices_metadata) + \";\")\n",
    "    print(\"Finished getting data for individual properties\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fae2fa09",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_city_owned():\n",
    "    print(\"Getting data for city-owned properties\")\n",
    "    # fetch data from the City-Owned Land Inventory dataset about all properties currently owned by the City of Chicago that might be up for sale (see http://dev.cityofchicago.org/open%20data/data%20portal/2020/08/11/city-owned-property.html)\n",
    "    city_owned = makeAPIRequest(\n",
    "        api_endpoint = get_dataset_url(city_owned_api_info, \"json\"),\n",
    "        params = [\n",
    "            \"$select=pin, managing_organization, date_of_acquisition, last_update\",\n",
    "            \"$where=(lower(property_status)='owned by city') AND (lower(managing_organization)='none' OR managing_organization IS NULL)\",\n",
    "        ],\n",
    "        limit = limit,\n",
    "        read_function = pd.read_json,\n",
    "    )\n",
    "    city_owned_metadata = get_metadata(city_owned_api_info)\n",
    "    \n",
    "    def standardize_date(date):\n",
    "        if pd.isna(date):\n",
    "            return date\n",
    "        else:\n",
    "            return datetime.datetime.strftime(datetime.datetime.strptime(date, \"%m/%d/%Y\"), \"%d %b %Y\")\n",
    "        \n",
    "    city_owned[\"pin\"] = city_owned[\"pin\"].str.replace(\"-\",\"\")\n",
    "    city_owned[\"date_of_acquisition\"] = city_owned[\"date_of_acquisition\"].apply(from_iso_format)\n",
    "    city_owned[\"last_update\"] = city_owned[\"last_update\"].apply(standardize_date)\n",
    "\n",
    "    city_owned_join = pd.merge(city_owned, properties, how=\"inner\", on=\"pin\", suffixes = [\"_aksk-kvfp\", \"_c49d-89sn\"])\n",
    "    count_of_no_updated_location_info = city_owned.shape[0] - city_owned_join.shape[0]\n",
    "    print(\"number of city-owned properties for which no location data from properties could be found:\", count_of_no_updated_location_info)\n",
    "\n",
    "    city_owned_metadata[\"dataUseNotes\"] = 'Only PINs where \"Property Status\" is \"owned by city\" and' \\\n",
    "    + ' \"Managing Organization\" is \"none\" or blank (using case-insensitive matching) have been included on the map' \\\n",
    "    + ' (based on the Open Data Portal Team\\'s' \\\n",
    "    + ' <a href=\"http://dev.cityofchicago.org/open%20data/data%20portal/2020/08/11/city-owned-property.html\">notes</a>' \\\n",
    "    + ' about the dataset). Up-to-date location information was obtained using the' \\\n",
    "    + f' <a href={properties_metadata[\"dataUri\"]}>\"{properties_metadata[\"name\"]}\"</a> dataset' \\\n",
    "    + f' ({count_of_no_updated_location_info} PINs for which no up-to-date location information could be found have been excluded).'\n",
    "    \n",
    "    city_owned_join.filter(items=[\n",
    "        \"pin\",\n",
    "        \"managing_organization\",\n",
    "        \"last_update\",\n",
    "        \"date_of_acquisition\",\n",
    "        \"property_address\",\n",
    "        \"property_zip\",\n",
    "        \"ward\",\n",
    "    ]).to_excel(\"city_owned_pins_possibly_for_sale.xlsx\", index=False)\n",
    "\n",
    "    city_owned_join = city_owned_join.set_index(\"pin\", drop=False)\n",
    "    \n",
    "    with open(\"../data/city-owned/city_owned_data.js\", \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(\"const city_owned_data = \")\n",
    "        f.write(city_owned_join.to_json(orient=\"index\") + \";\")\n",
    "        f.write(\"\\n\\nconst city_owned_metadata = \")\n",
    "        f.write(json.dumps(city_owned_metadata) + \";\")\n",
    "    print(\"Finished getting data for city-owned properties\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9b2885cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_business_licenses():\n",
    "    print(\"Getting data for business licenses\")\n",
    "    business_licenses = makeAPIRequest(\n",
    "        api_endpoint = get_dataset_url(business_licenses_api_info, \"json\"),\n",
    "        params = [\n",
    "            \"$select=license_number, license_id, doing_business_as_name, license_description, business_activity, address, zip_code, longitude, latitude, license_start_date\",\n",
    "            \"$where=ward='20' AND (latitude IS NOT NULL) AND (longitude IS NOT NULL)\",\n",
    "        ],\n",
    "        limit = limit,\n",
    "        read_function = pd.read_json,\n",
    "    )\n",
    "    business_licenses_metadata = get_metadata(business_licenses_api_info)\n",
    "    business_licenses_metadata[\"dataUseNotes\"] = 'Only information about the most recent licenses for businesses with valid coordinates in Ward 20 has been included on the map.'\n",
    "    \n",
    "    # filter out duplicate entries for the same license number, keeping only the entry with the most recent license start date\n",
    "    business_licenses_filtered = business_licenses.sort_values(by=['license_number', 'license_start_date']).drop_duplicates(subset=['license_number'], keep='last').drop(columns=['license_number','license_start_date'])\n",
    "    \n",
    "    # aggregate licenses into a single entry for each address of each business\n",
    "    business_licenses_aggregated = business_licenses_filtered.groupby(by=[\"doing_business_as_name\", \"address\"]).agg(set_aggregation_function).reset_index()    \n",
    "    with open(\"../data/business-licenses/business_license_data.js\", \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(\"const business_license_data = \")\n",
    "        f.write(business_licenses_aggregated.to_json(orient=\"records\") + \";\")\n",
    "        f.write(\"\\n\\nconst business_licenses_metadata = \")\n",
    "        f.write(json.dumps(business_licenses_metadata) + \";\")\n",
    "    print(\"Finished getting data for business licenses\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4f3d4740",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_scavenger_sale():\n",
    "    print(\"Getting data for scavenger sale\")\n",
    "    # scavenger sale data from 28 January 2022 (source: https://web.archive.org/web/20220128184252/https://www.cookcountytreasurer.com/pdfs/scavsale/2022cookcountyscavengertaxsalelist.xlsx, accessed 3 June 2022)\n",
    "    scavenger = pd.read_excel(\"../data/scavenger-sale/2022cookcountyscavengertaxsalelist_1-28-22.xlsx\")\n",
    "    standardize_columns(scavenger)\n",
    "    scavenger[\"pin\"] = scavenger[\"pin\"].str.replace(\"-\", \"\")\n",
    "    scavenger[\"classification\"] = scavenger[\"classification\"].str.strip()\n",
    "    \n",
    "    # property class data (source: https://www.cookcountyassessor.com/form-document/codes-classification-property, accessed 22 June 2022)\n",
    "    property_classes = pd.read_excel(\"../data/scavenger-sale/property_classes.xlsx\")\n",
    "    # join scavenger sale data with property class data\n",
    "    scavenger_with_property_classes = pd.merge(scavenger, property_classes, how=\"left\", left_on = \"classification\", right_on=\"property_code\").drop(columns=['classification'])\n",
    "    # make sure all scavenger sale entries have associated property class data\n",
    "    assert scavenger_with_property_classes[pd.isna(scavenger_with_property_classes['property_code'])].shape[0] == 0\n",
    "    \n",
    "    # get location data for pins on scavenger sale list\n",
    "    scavenger_final_join = pd.merge(scavenger_with_property_classes, properties, how=\"inner\", on=\"pin\", suffixes=[\"_scavenger_sale\", \"_c49d-89sn\"])\n",
    "    # make sure all pins on scavenger sale list have associated location data\n",
    "    assert scavenger_final_join.shape[0] == scavenger_with_property_classes.shape[0]\n",
    "    scavenger_final_join = scavenger_final_join[scavenger_final_join['ward'] == 20].filter(items = [\n",
    "        'pin',\n",
    "        'property_address_scavenger_sale',\n",
    "        'delinquent_tax_year_range',\n",
    "        'delinquent_tax',\n",
    "        'delinquent_interest',\n",
    "        'total_delinquency',\n",
    "        'property_code_meaning',\n",
    "        'property_code_class',\n",
    "        'property_zip',\n",
    "        'longitude',\n",
    "        'latitude',\n",
    "    ]).rename(columns = {\n",
    "        'property_address_scavenger_sale' : 'property_address',\n",
    "    }).set_index('pin', drop=False)\n",
    "    # make sure there are no duplicated entries for pins\n",
    "    assert scavenger_final_join.index.unique().shape[0] == scavenger_final_join.index.shape[0]\n",
    "    \n",
    "    scavenger_sale_metadata = {\n",
    "        'id': None,\n",
    "        'name': '2022 Cook County Scavenger Tax Sale List',\n",
    "        'description': 'Properties scheduled to be offered at the 2022 Scavenger Sale.',\n",
    "        'dataUri': 'https://web.archive.org/web/20220128181637/https://www.cookcountytreasurer.com/scavengersalemap.aspx',\n",
    "        'attribution': 'Cook County Treasurer',\n",
    "        'attributionLink': 'https://www.cookcountytreasurer.com/',\n",
    "        'actualDatasourceUri': 'https://web.archive.org/web/20220128184252/https://www.cookcountytreasurer.com/pdfs/scavsale/2022cookcountyscavengertaxsalelist.xlsx',\n",
    "        'createdAt': None,\n",
    "        'dataUpdatedAt': '28 January 2022',\n",
    "        'metadataUpdatedAt': None,\n",
    "        'accessedOn': '3 Jun 2022',\n",
    "        'dataUseNotes': 'Only PINs in Ward 20 have been included on the map.' \\\n",
    "        + ' Location information was obtained using the' \\\n",
    "        + f' <a href={properties_metadata[\"dataUri\"]}>\"{properties_metadata[\"name\"]}\"</a> dataset.'\n",
    "    }\n",
    "    \n",
    "    property_classification_codes_metadata = {\n",
    "        'id': None,\n",
    "        'name': 'Definitions for the Codes for Classification of Real Property',\n",
    "        'description': 'Definitions for the codes for classification of real property.',\n",
    "        'dataUri': 'https://prodassets.cookcountyassessor.com/s3fs-public/form_documents/classcode.pdf?VersionId=12JVr.oX..WD4hfgjLCp5AIVfar71ndn',\n",
    "        'attribution': 'Cook County Assessor',\n",
    "        'attributionLink': 'https://www.cookcountyassessor.com/',\n",
    "        'actualDatasourceUri': None,\n",
    "        'createdAt': '03 April 2018',\n",
    "        'dataUpdatedAt': None,\n",
    "        'metadataUpdatedAt': None,\n",
    "        'accessedOn': '22 Jun 2022',\n",
    "    }\n",
    "    \n",
    "    with open(\"../data/scavenger-sale/scavenger_data.js\", \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(\"const scavenger_sale_data = \") # assign join JSON data to variable for easier access by JavaScript scripts in browser\n",
    "        f.write(scavenger_final_join.to_json(orient=\"index\") + \";\") # output as JSON\n",
    "        f.write(\"\\n\\nconst scavenger_sale_metadata = \")\n",
    "        f.write(json.dumps(scavenger_sale_metadata) + \";\")\n",
    "        f.write(\"\\n\\nconst property_classification_codes_metadata = \")\n",
    "        f.write(json.dumps(property_classification_codes_metadata) + \";\")\n",
    "    print(\"Finished getting data for scavenger sale\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "954745a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tax_sale_2019():\n",
    "    print(\"Getting data for Ward 20 2019 tax sale\")\n",
    "    # Ward 20 Properties on Tax Sale list for Tax Year 2019, accessed on 17 May 2022 around 11 am ET\n",
    "    taxsale = pd.read_excel(\"../data/tax-sale/tax_sale_tax_year_2019_ward20_accessed_17_May_2022.xlsx\")\n",
    "    standardize_columns(taxsale)\n",
    "    taxsale['pin'] = taxsale['pin'].str.replace('-', '')\n",
    "    taxsale = taxsale.filter(items=[\n",
    "        'pin',\n",
    "        'property_address',\n",
    "        'current_mailing_address',\n",
    "        'taxpayer_name',\n",
    "        'tax_type',\n",
    "        'tax_year',\n",
    "        'total_tax_due',\n",
    "        'total_due_(including_interest)',\n",
    "        'classification',\n",
    "    ])\n",
    "    taxsale = taxsale[taxsale['tax_year'] == 2019].drop(columns=['tax_year'])\n",
    "    # make sure no entries have duplicate pins\n",
    "    assert taxsale['pin'].shape[0] == taxsale['pin'].unique().shape[0]\n",
    "    \n",
    "    taxsale_join = pd.merge(taxsale, properties, how=\"inner\", on=\"pin\", suffixes=[\"_tax_sale\", \"_c49d-89sn\"])\n",
    "    # make sure all pins have associated location data and are in Ward 20\n",
    "    assert taxsale_join.shape[0] == taxsale.shape[0]\n",
    "    taxsale_join = taxsale_join.drop(columns=[\n",
    "        'property_address_c49d-89sn',\n",
    "    ]).rename(columns={\n",
    "        'property_address_tax_sale' : 'property_address',\n",
    "        'total_due_(including_interest)' : 'total_due_including_interest',\n",
    "    }).set_index('pin', drop=False)\n",
    "    \n",
    "    taxsale_metadata = {\n",
    "        'id': None,\n",
    "        'name': 'Delinquent Tax Report for Tax Year 2019 for Ward 20',\n",
    "        'description': 'Properties in Ward 20 with delinquent taxes for Tax Year 2019 (payable in 2020) that were eligible at the time of access for the Annual Tax Sale scheduled for May 2022.',\n",
    "        'dataUri': 'https://www.cookcountytreasurer.com/delinquenttaxes.aspx',\n",
    "        'attribution': 'Cook County Treasurer',\n",
    "        'attributionLink': 'https://www.cookcountytreasurer.com/',\n",
    "        'actualDatasourceUri': None,\n",
    "        'createdAt': None,\n",
    "        'dataUpdatedAt': None,\n",
    "        'metadataUpdatedAt': None,\n",
    "        'accessedOn': '17 Jun 2022',\n",
    "        'dataUseNotes': 'Only PINs with tax due for Tax Year 2019 have been included on the map.' \\\n",
    "        + ' Location information was obtained using the' \\\n",
    "        + f' <a href={properties_metadata[\"dataUri\"]}>\"{properties_metadata[\"name\"]}\"</a> dataset.'\n",
    "    }\n",
    "    \n",
    "    with open(\"../data/tax-sale/taxsale_2019.js\", \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(\"const taxsale_2019_data = \") # assign JSON data to variable for easier access by JavaScript scripts in browser\n",
    "        f.write(taxsale_join.to_json(orient=\"index\") + \";\") # output as JSON\n",
    "        f.write(\"\\n\\nconst taxsale_2019_metadata = \")\n",
    "        f.write(json.dumps(taxsale_metadata) + \";\")\n",
    "    print(\"Finished getting data for Ward 20 2019 tax sale\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "61d3eaa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tax_sale_2020():\n",
    "    print(\"Getting data for Ward 20 2020 tax sale\")\n",
    "    # Ward 20 Properties on Tax Sale list for Tax Year 2020 as of 8 June 2022, downloaded in the form of reports organized by commissioner district on 22 June 2022, extracted from PDFs using tabula-py\n",
    "    taxsale = pd.read_excel(\"../data/tax-sale/TaxSale2020_Ward20_as_of_8_June_2022.xlsx\")\n",
    "    standardize_columns(taxsale)\n",
    "    taxsale.columns = taxsale.columns.str.replace('_x000d_','_')\n",
    "    taxsale['pin'] = taxsale['pin'].str.replace('-', '')\n",
    "    taxsale = taxsale.filter(items=[\n",
    "        'pin',\n",
    "        'property_address',\n",
    "        'current_mailing_address',\n",
    "        'taxpayer_name',\n",
    "        'tax_type',\n",
    "        'tax_year',\n",
    "        'total_tax_due',\n",
    "        'total_due_(including_interest)',\n",
    "        'classification',\n",
    "    ])\n",
    "    taxsale = taxsale[taxsale['tax_year'] == 2020].drop(columns=['tax_year'])\n",
    "    # make sure no entries have duplicate pins\n",
    "    assert taxsale['pin'].shape[0] == taxsale['pin'].unique().shape[0]\n",
    "    \n",
    "    taxsale_join = pd.merge(taxsale, properties, how=\"inner\", on=\"pin\", suffixes=[\"_tax_sale\", \"_c49d-89sn\"])\n",
    "    # make sure all pins have associated location data and are in Ward 20\n",
    "    assert taxsale_join.shape[0] == taxsale.shape[0]\n",
    "    taxsale_join = taxsale_join.drop(columns=[\n",
    "        'property_address_c49d-89sn',\n",
    "    ]).rename(columns={\n",
    "        'property_address_tax_sale' : 'property_address',\n",
    "        'total_due_(including_interest)' : 'total_due_including_interest',\n",
    "    }).set_index('pin', drop=False)\n",
    "    \n",
    "    taxsale_metadata = {\n",
    "        'id': None,\n",
    "        'name': 'Properties Currently Eligible for 2020 Annual Tax Sale',\n",
    "        'description': 'Properties in Ward 20 with delinquent taxes for Tax Year 2020 (payable in 2021) that were eligible at the time of access for the Annual Tax Sale scheduled for November 2022.',\n",
    "        'dataUri': 'https://www.cookcountytreasurer.com/delinquenttaxes.aspx',\n",
    "        'attribution': 'Cook County Treasurer',\n",
    "        'attributionLink': 'https://www.cookcountytreasurer.com/',\n",
    "        'actualDatasourceUri': None,\n",
    "        'createdAt': None,\n",
    "        'dataUpdatedAt': '08 Jun 2022',\n",
    "        'metadataUpdatedAt': None,\n",
    "        'accessedOn': '22 Jun 2022',\n",
    "        'dataUseNotes': 'Only PINs with tax due for Tax Year 2020 have been included on the map.' \\\n",
    "        + ' Location information was obtained using the' \\\n",
    "        + f' <a href={properties_metadata[\"dataUri\"]}>\"{properties_metadata[\"name\"]}\"</a> dataset.'\n",
    "    }\n",
    "    \n",
    "    with open(\"../data/tax-sale/taxsale_2020.js\", \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(\"const taxsale_2020_data = \") # assign JSON data to variable for easier access by JavaScript scripts in browser\n",
    "        f.write(taxsale_join.to_json(orient=\"index\") + \";\") # output as JSON\n",
    "        f.write(\"\\n\\nconst taxsale_2020_metadata = \")\n",
    "        f.write(json.dumps(taxsale_metadata) + \";\")\n",
    "    print(\"Finished getting data for Ward 20 2020 tax sale\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "10c654e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting data for ward boundaries\n",
      "reviewableUid found for WARDS_2015\n",
      "Finished getting data for ward boundaries\n",
      "Getting data for neighborhood boundaries\n",
      "reviewableUid found for Neighborhoods_2012b\n",
      "Finished getting data for neighborhood boundaries\n",
      "Getting data for zoning districts\n",
      "reviewableUid found for zoning_2016_01\n",
      "Finished getting data for zoning districts\n",
      "Getting data for school locations\n",
      "Finished getting data for school_locations\n",
      "Getting data for individual properties\n",
      "Finished getting data for individual properties\n",
      "Getting data for city-owned properties\n",
      "number of city-owned properties for which no location data from properties could be found: 6\n",
      "Finished getting data for city-owned properties\n",
      "Getting data for business licenses\n",
      "Finished getting data for business licenses\n",
      "Getting data for scavenger sale\n",
      "Finished getting data for scavenger sale\n",
      "Getting data for Ward 20 2019 tax sale\n",
      "Finished getting data for Ward 20 2019 tax sale\n",
      "Getting data for Ward 20 2020 tax sale\n",
      "Finished getting data for Ward 20 2020 tax sale\n"
     ]
    }
   ],
   "source": [
    "# comment out the functions that should not be called\n",
    "get_ward_boundaries()\n",
    "get_neighborhood_boundaries()\n",
    "get_zoning_districts()\n",
    "get_school_locations()\n",
    "get_individual_properties()\n",
    "get_city_owned()\n",
    "get_business_licenses()\n",
    "get_scavenger_sale()\n",
    "get_tax_sale_2019()\n",
    "get_tax_sale_2020()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
